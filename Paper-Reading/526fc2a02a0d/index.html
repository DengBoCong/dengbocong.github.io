<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<link rel="stylesheet" href="/css/search.css">
<script src="/js/jquery-3.4.1.min.js"></script>
<script src="/js/search.js"></script>
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #5cb0ff; /*进度条颜色*/
        height: 2px;
    }
    .pace .pace-progress-inner {
        box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>

    <meta name="author" content="DengBoCong">


    <meta name="subtitle" content="NLP | Deep Learning | Java">




<title>论文阅读笔记：快速的评估选择适合下游任务的预训练模型 | DengBoCong</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


    


<meta name="generator" content="Hexo 5.3.0"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">DengBoCong</a></div>
            <div class="menu navbar-right">
                <div class="search" style="float: left; margin-top: 7px;">
                    <form class="form-search">
                        <input class="input" placeholder="search content..." autocomplete="off" onchange="inputChange(event)" id="pc-search-input"/>
                    </form>
                    <div class="search-btn">
                        <img src="/image/search.png" class="search-btn-img" />
                    </div>
                </div>
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/projects">Projects</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">DengBoCong</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/projects">Projects</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">论文阅读笔记：快速的评估选择适合下游任务的预训练模型</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">DengBoCong</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">March 22, 2021&nbsp;&nbsp;10:28:41</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/Paper-Reading/">Paper-Reading</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><blockquote>
<p>标题：LogME: Practical Assessment of Pre-trained Models for Transfer Learning<br>原文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2102.11005.pdf">Link</a><br>nlp-paper：<a target="_blank" rel="noopener" href="https://github.com/DengBoCong/nlp-paper">NLP相关Paper笔记和代码复现</a><br>nlp-dialogue：<a target="_blank" rel="noopener" href="https://github.com/DengBoCong/nlp-dialogue">一个开源的全流程对话系统，更新中！</a><br>说明：阅读原文时进行相关思想、结构、优缺点，内容进行提炼和记录，原文和相关引用会标明出处，引用之处如有侵权，烦请告知删除。<br>转载请注明：DengBoCong</p>
</blockquote>
<p>在NLP领域，预训练模型（准确的说应该是预训练语言模型）似乎已经成为各大任务必备的模块了，经常有看到文章称后BERT时代或后XXX时代，分析对比了许多主流模型的优缺点，这些相对而言有些停留在理论层面，可是有时候对于手上正在解决的任务，要用到预训练语言模型时，面对烟火缭乱的语言模型，需要如何挑选合适的模型应用到任务上来。</p>
<p>一个非常直接的方法就是把每一个候选模型针对任务都做一遍微调，因为微调涉及到模型训练，时间至少几个小时起步。有些预训练模型的微调还需要进行超参数搜索，想要决定一个预训练模型的迁移效果就需要将近50个小时！对于没有足够算力的我，苦苦寻觅一个能够高效的选择适合的预训练语言模型的方法，不过资料不好找呀，偶然间我才发现了这篇论文，里面提到的LogME方法值得一试。下图是该方法适配的任务：<br><img src="https://img-blog.csdnimg.cn/20210321224833785.png#pic_center" alt="在这里插入图片描述"></p>
<p>多提一下，我这里说的是预训练语言模型，即在适用于NLP领域内的模型选择打分，而对于适用于CV的一些打分方案，像LEEP、NCE、H scores感兴趣的小伙伴可以找论文看看。</p>
<p>本文在LogME方法的相关描述上，组织基于论文作者所在学院的官方公众号上的一篇文章，可<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/9lJEcwkXAN4jaENNghjpyw">直戳原文阅读</a>。<strong>原Paper中开源的代码使用Pytorch进行GPU加速，我在本文的最后附上我改成TensorFlow2的代码，方便直接应用在TensorFlow2的相关模型上。</strong></p>
<h1 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h1><p>将上面提到的问题，描述成图模型，就是论文中所画出如下的这样：<br><img src="https://img-blog.csdnimg.cn/20210321223707890.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RCQ18xMjE=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在这个任务中，我们假设有 $M$ 个预训练模型组成的集合 ${\phi_m}^M_{m=1}$ 和 含有 $n$ 个标签的数据集 ${(x_i,y_i)}^n_{i=1}$，正常情况下，我们是通过微调使用各种评判指标作为衡量模型 $\phi$ 的表现 $T_m$，而现在我们想要通过一种方法得到 $S_m$，其中 ${S_m}^M_{m=1}$ 能够与 ${T_m}^M_{m=1}$ 有着很好的相关性。</p>
<p>简单来说就是预训练模型选择问题，就是针对用户给定的数据集，从预训练模型库中选择一个最适合的预训练模型用于迁移学习，核心就是要对每一个预训练模型进行迁移性评估(Transferability Assessment)，为每个模型打分，然后选择出打分最高的预训练模型。</p>
<h1 id="LogME方法"><a href="#LogME方法" class="headerlink" title="LogME方法"></a>LogME方法</h1><p>LogME的优越性能来自于以下三个方面：</p>
<h3 id="无须梯度计算"><a href="#无须梯度计算" class="headerlink" title="无须梯度计算"></a>无须梯度计算</h3><p>为了加速预训练模型选择，我们仅将预训练模型 $\phi$ 视作特征提取器，避免更新预训练模型 $\phi$ 。这样，只需要将预训练模型在给定数据集上前向传播一遍，就可以得到特征 ${f_i=\phi(x_i)}^n_{i=1}$ 和标注 ${y_i}^n_{n=1}$。于是，这个问题就转化成了如何衡量特征和标注之间的关系，也就是说，这些特征能够多大程度上用于预测这些标注。</p>
<p>为此，我们采用一般性的统计方法，用概率密度 $p(y|F)$ 来衡量特征与标注的关系。考虑到微调一般就是在预训练模型的特征提取层之上再加一个线性层，所以我们用一个线性层来建模特征与标注的关系。</p>
<p>说到这里，很多人会想到，一种直观的方法是通过Logistic Regression或者Linear Regression得到最优权重 $w^*$，然后使用似然函数 $p(y|F,w^*)$ 作为打分标准。但是但是这相当于训练一个模型来建模问题，这样容易导致过拟合问题，而且这些方法也有很多超参数需要选择，这使得它们的时间开销很大且效果不好。</p>
<h3 id="无须超参数调优"><a href="#无须超参数调优" class="headerlink" title="无须超参数调优"></a>无须超参数调优</h3><p>为了避免超参数进行调优，论文中的方法选用的是统计学中的证据(evidence，也叫marginalized likelihood，即<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BE%B9%E7%BC%98%E4%BC%BC%E7%84%B6">边缘似然</a>)来衡量特征与标注的关系。它不使用某个特定的 $w^*$ 的值，而是使用 $w$ 的分布 $p(w)$ 来得到边缘化似然的值 $p(y|F)=\int p(w)p(y|F,w)dw$。它相当于取遍了所有可能的 $w$ 值，能够更加准确地反映特征与标注的关系，不会有过拟合的问题。其中，$p(w)$ 与 $p(y|F,w)$ 分别由超参数 $\alpha$ 和 $\beta$ 决定，但是它们不需要 grid search，可以通过最大化evidence来直接求解。于是，我们就得到了对数最大证据(Log Maximum Evidence, 缩写LogME)标准来作为预训练模型选择的依据，如下图：<br><img src="https://img-blog.csdnimg.cn/2021032123393016.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RCQ18xMjE=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>数学推导不在这里赘述了，感兴趣的小伙伴戳原文阅读，该方法的具体细节在下图中给出了，注意，虽然LogME计算过程中将预训练模型视作特征提取器，但是LogME可以用于衡量被用于迁移学习(微调)的性能：<br><img src="https://img-blog.csdnimg.cn/20210321234241726.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RCQ18xMjE=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="算法实现优化"><a href="#算法实现优化" class="headerlink" title="算法实现优化"></a>算法实现优化</h3><p>值得一提的是，LogME算法涉及到很多矩阵分解、求逆、相乘操作，因此一不小心就容易使得算法的复杂度很高(例如上图第9行，粗糙的实现方式)。我们在深入研究该算法后发现，很多矩阵运算的开销可以通过巧妙的计算优化手段大大降低，因此将计算流程优化为上图第10行，整体的计算复杂度降低了一个阶，从四次方降低为三次方(见下表)，使得该算法在数秒内就能处理常见情况：<br><img src="https://img-blog.csdnimg.cn/20210321234436218.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p>在实验部分，我们用合成数据、真实数据等多种方式方式，测试了LogME在17个数据集、14个预训练模型上的效果，LogME在这么多数据集、预训练模型上都表现得很好，展现了它优异的性能。</p>
<p>首先让我们看看，LogME给出的打分标准与人的主观感觉是否一致。我们为分类问题和回归问题分别设计了一个toy实验，使用生成数据来测量LogME的值。从下图中可以看出，不管是分类任务还是回归任务，当特征质量越来越差时，LogME的值也越来越低，说明LogME可以很好地衡量特征与标注的关系，从而作为预训练模型选择的标准：<br><img src="https://img-blog.csdnimg.cn/20210321235112104.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RCQ18xMjE=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>接下来，用LogME来进行预训练模型选择。使用若干个常用预训练模型，通过耗时的微调过程得到它们的迁移性指标，然后衡量LogME与迁移性指标的相关性。相关性指标为加权肯达尔系数 $\tau_w$，它的取值范围是 $[-1,1]$。相关系数为 $\tau_w$ 意味着如果LogME认为预训练模型 $\phi_1$ 比 $\phi_2$ 好，那么 $\phi_1$ 确实比 $\phi_2$ 好的概率是 $\frac{\tau_w+1}{2}$。也就是说，$\tau_w$ 越大越好。</p>
<p>将10个常用预训练模型迁移到9个常见分类数据集中，发现LogME与微调准确率有很高的相关性(见下图)，显著优于之前的LEEP和NCE方法。在这几个数据集中，LogME的相关系数 $\tau_w$  至少有0.5，大部分情况下有0.7或者0.8，也就意味着使用LogME进行预训练模型选择的准确率高达85%或者90%：<br><img src="https://img-blog.csdnimg.cn/20210321235634651.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RCQ18xMjE=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在回归任务的实验中，如下图可以看到LogME与MSE有明显的负相关性，而MSE是越低越好，LogME是越大越好，结果符合预期：<br><img src="https://img-blog.csdnimg.cn/2021032123580732.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RCQ18xMjE=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>下图可以看到，在五个任务上，LogME完美地预测了四个预训练模型的表现的相对大小，在另外两个任务上的表现也不错。<br><img src="https://img-blog.csdnimg.cn/20210322000146472.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RCQ18xMjE=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>LogME方法不仅效果好，更难得的是它所需要的时间非常短，可以快速评价预训练模型。如果将直接微调的时间作为基准，LogME只需要0.31‰的时间(注意不是百分号，是千分号)，也就是说加速了3000倍！而之前的方法如LEEP和NCE，虽然耗时更少，但是效果很差，适用范围也很有限，完全不如LogME方法：<br><img src="https://img-blog.csdnimg.cn/20210322000302184.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RCQ18xMjE=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h1 id="TensorFlow2代码"><a href="#TensorFlow2代码" class="headerlink" title="TensorFlow2代码"></a>TensorFlow2代码</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from numba import njit</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@njit</span><br><span class="line">def each_evidence(y_, f, fh, v, s, vh, N, D):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    compute the maximum evidence for each class</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    alpha &#x3D; 1.0</span><br><span class="line">    beta &#x3D; 1.0</span><br><span class="line">    lam &#x3D; alpha &#x2F; beta</span><br><span class="line">    tmp &#x3D; (vh @ (f @ y_))</span><br><span class="line">    for _ in range(11):</span><br><span class="line">        gamma &#x3D; (s &#x2F; (s + lam)).sum()</span><br><span class="line">        m &#x3D; v @ (tmp * beta &#x2F; (alpha + beta * s))</span><br><span class="line">        alpha_de &#x3D; (m * m).sum()</span><br><span class="line">        alpha &#x3D; gamma &#x2F; alpha_de</span><br><span class="line">        beta_de &#x3D; ((y_ - fh @ m) ** 2).sum()</span><br><span class="line">        beta &#x3D; (N - gamma) &#x2F; beta_de</span><br><span class="line">        new_lam &#x3D; alpha &#x2F; beta</span><br><span class="line">        if np.abs(new_lam - lam) &#x2F; lam &lt; 0.01:</span><br><span class="line">            break</span><br><span class="line">        lam &#x3D; new_lam</span><br><span class="line">    evidence &#x3D; D &#x2F; 2.0 * np.log(alpha) \</span><br><span class="line">                + N &#x2F; 2.0 * np.log(beta) \</span><br><span class="line">                - 0.5 * np.sum(np.log(alpha + beta * s)) \</span><br><span class="line">                - beta &#x2F; 2.0 * beta_de \</span><br><span class="line">                - alpha &#x2F; 2.0 * alpha_de \</span><br><span class="line">                - N &#x2F; 2.0 * np.log(2 * np.pi)</span><br><span class="line">    return evidence &#x2F; N</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># D &#x3D; 20, N &#x3D; 50</span><br><span class="line">f_tmp &#x3D; np.random.randn(20, 50).astype(np.float64)</span><br><span class="line">each_evidence(np.random.randint(0, 2, 50).astype(np.float64), f_tmp, f_tmp.transpose(),</span><br><span class="line">                np.eye(20, dtype&#x3D;np.float64), np.ones(20, dtype&#x3D;np.float64), np.eye(20, dtype&#x3D;np.float64), 50,</span><br><span class="line">                20)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def LogME(f: tf.Tensor, y: tf.Tensor, regression&#x3D;False):</span><br><span class="line">    f &#x3D; f.numpy().astype(np.float64)</span><br><span class="line">    y &#x3D; y.numpy()</span><br><span class="line">    if regression:</span><br><span class="line">        y &#x3D; y.numpy().astype(np.float64)</span><br><span class="line"></span><br><span class="line">    fh &#x3D; f</span><br><span class="line">    f &#x3D; f.transpose()</span><br><span class="line">    D, N &#x3D; f.shape</span><br><span class="line">    v, s, vh &#x3D; np.linalg.svd(f @ fh, full_matrices&#x3D;True)</span><br><span class="line"></span><br><span class="line">    evidences &#x3D; []</span><br><span class="line">    if regression:</span><br><span class="line">        K &#x3D; y.shape[1]</span><br><span class="line">        for i in range(K):</span><br><span class="line">            y_ &#x3D; y[:, i]</span><br><span class="line">            evidence &#x3D; each_evidence(y_, f, fh, v, s, vh, N, D)</span><br><span class="line">            evidences.append(evidence)</span><br><span class="line">    else:</span><br><span class="line">        K &#x3D; int(y.max() + 1)</span><br><span class="line">        for i in range(K):</span><br><span class="line">            y_ &#x3D; (y &#x3D;&#x3D; i).astype(np.float64)</span><br><span class="line">            evidence &#x3D; each_evidence(y_, f, fh, v, s, vh, N, D)</span><br><span class="line">            evidences.append(evidence)</span><br><span class="line">    return np.mean(evidences)</span><br></pre></td></tr></table></figure>
        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>DengBoCong</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="http://dengbocong.cn/Paper-Reading/526fc2a02a0d/">http://dengbocong.cn/Paper-Reading/526fc2a02a0d/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Licensed under the Apache License, Version 2.0 (the "License")</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span>Stay hungry, Stay foolish.</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"># 预训练模型</a>
                    
                        <a href="/tags/%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95/"># 评估方法</a>
                    
                        <a href="/tags/%E5%BE%AE%E8%B0%83/"># 微调</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/Deep-Learning/58cb665371b1/">关于Transformer几个内部细节的总结</a>
            
            
            <a class="next" rel="next" href="/Paper-Reading/bb40f25f3748/">论文阅读笔记：这篇文章教你在文本分类任务上微调BERT</a>
            
        </section>


    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© Copyright 2020-2021 DengBoCong. All Rights Reserved. 赣ICP备20002291号</span>
    </div>
</footer>

    </div>
    <div id="u-search">
        <div class="modal">
            <div class="modal-header">
                <div class="container">
                    <form id="u-search-modal-form" class="u-search-modal-form">
                        <button type="submit" class="form-submit-btn">
                            <img src="/image/search.png" class="search-btn-img" />
                        </button>
                        <input placeholder="请输入关键字搜索文章..." class="form-input" onchange="inputChange(event)" id="modal-form-input">
                    </form>
                    <a class="modal-close">x</a>
                </div>
                <div class="search-loading">
                    <div class="search-loading-bar"></div>
                </div>
            </div>
            <div class="modal-body">
            </div>
        </div>
        <div class="modal-overlay"></div>
    </div>
</body>
</html>
