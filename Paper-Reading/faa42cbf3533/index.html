<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<link rel="stylesheet" href="/css/search.css">
<script src="/js/jquery-3.4.1.min.js"></script>
<script src="/js/search.js"></script>
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #5cb0ff; /*进度条颜色*/
        height: 2px;
    }
    .pace .pace-progress-inner {
        box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>

    <meta name="author" content="DengBoCong">


    <meta name="subtitle" content="NLP | Deep Learning | Java">




<title>论文阅读笔记：XLNet--自回归语言模型的复兴 | DengBoCong</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


    


<meta name="generator" content="Hexo 5.3.0"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">DengBoCong</a></div>
            <div class="menu navbar-right">
                <div class="search" style="float: left; margin-top: 7px;">
                    <form class="form-search">
                        <input class="input" placeholder="search content..." autocomplete="off" onchange="inputChange(event)" id="pc-search-input"/>
                    </form>
                    <div class="search-btn">
                        <img src="/image/search.png" class="search-btn-img" />
                    </div>
                </div>
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/projects">Projects</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">DengBoCong</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/projects">Projects</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">论文阅读笔记：XLNet--自回归语言模型的复兴</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">DengBoCong</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">April 2, 2021&nbsp;&nbsp;9:26:07</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/Paper-Reading/">Paper-Reading</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><blockquote>
<p>标题：XLNet: Generalized Autoregressive Pretraining for Language Understanding<br>原文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1906.08237.pdf">Link</a><br>nlp-paper：<a target="_blank" rel="noopener" href="https://github.com/DengBoCong/nlp-paper">NLP相关Paper笔记和代码复现</a><br>nlp-dialogue：<a target="_blank" rel="noopener" href="https://github.com/DengBoCong/nlp-dialogue">一个开源的全流程对话系统，更新中！</a><br>说明：阅读原文时进行相关思想、结构、优缺点，内容进行提炼和记录，原文和相关引用会标明出处，引用之处如有侵权，烦请告知删除。<br>转载请注明：DengBoCong</p>
</blockquote>
<p>Google发布的XLNet在问答、文本分类、自然语言理解等任务上都大幅超越BERT，XLNet提出一个框架来连接语言建模方法和预训练方法。我们所熟悉的BERT是denoising autoencoding模型，最大的亮点就是能够获取上下文相关的双向特征表示，所以相对于标准语言模型（自回归）的预训练方法相比，基于BERT的预训练方法具有更好的性能，但是这种结构同样使得BERT有着它的缺点：</p>
<ul>
<li>生成任务表现不佳：预训练过程和生成过程的不一致，导致在生成任务上效果不佳；</li>
<li>采取独立性假设：没有考虑预测[MASK]之间的相关性（位置之间的依赖关系），是对语言模型联合概率的有偏估计（不是密度估计）；</li>
<li>输入噪声[MASK]，造成预训练-精调两阶段之间的差异；</li>
<li>无法适用在文档级别的NLP任务，只适合于句子和段落级别的任务；</li>
</ul>
<p>鉴于这些利弊，作者提出一种广义自回归预训练方法XLNet，该方法：</p>
<ul>
<li>enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization orde</li>
<li>overcomes the limitations of BERT thanks to its autoregressive formulation</li>
</ul>
<h1 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h1><p>首先在此之前需要了解一下预训练语言模型的相关联系和背景，这里推荐两篇文章，一篇是邱锡鹏老师的关于NLP预训练模型的总结Paper：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2003.08271.pdf">Pre-trained Models for Natural Language Processing: A Survey</a>，我之前对它有写过阅读笔记：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/352152573">论文阅读笔记：超详细的NLP预训练语言模型总结清单！</a>，还有一篇就是：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/76912493">nlp中的预训练语言模型总结(单向模型、BERT系列模型、XLNet)</a>，其中总结的也相当的全面精辟到位。</p>
<p>目前无监督表示学习这一块，自回归（autogression）语言建模和自动编码（autoencoding）无疑是最成功的两个。对于ELMO、GPT等预训练模型都是基于传统的语言模型（自回归语言模型AR），自回归语言模型天然适合处理生成任务，但是无法对双向上下文进行表征，因此人们反而转向自编码思想的研究（如BERT系列模型）。</p>
<p>那AE就完美了嘛？自编码语言模型（AE）虽然可以实现双向上下文进行表征，但是依旧存在不适于生成任务的问题，就和上面说的BERT的缺点一样，以BERT为代表的系列模型：</p>
<ul>
<li>BERT系列模型引入独立性假设，没有考虑预测[MASK]之间的相关性；</li>
<li>MLM预训练目标的设置造成预训练过程和生成过程不一致；</li>
<li>预训练时的[MASK]噪声在finetune阶段不会出现，造成两阶段不匹配问题；</li>
</ul>
<p>对于AE和AR两种模型在各自的方向优点，有什么办法能构建一个模型使得同时具有AR和AE的优点并且没有它们缺点呢？这也是XLNet诞生的初衷，对于XLNet：</p>
<ul>
<li>不再像传统AR模型中那样使用前向或者反向的固定次序作为输入，XLNet引入排列语言模型，采用排列组合的方式，每个位置的上下文可以由来自左边和右边的token组成。在期望中，每个位置都要学会利用来自所有位置的上下文信息，即，捕获双向上下文信息。</li>
<li>作为一个通用的AR语言模型，XLNet不再使用data corruption，即不再使用特定标识符号[MASK]。因此也就不存在BERT中的预训练和微调的不一致性。同时，自回归在分解预测tokens的联合概率时，天然地使用乘法法则，这消除了BERT中的独立性假设。</li>
<li>XLNet在预训练中借鉴了Transformer-XL中的segment recurrence机制的相对编码方案，其性能提升在长文本序列上尤为显著。</li>
<li>由于分解后次序是任意的，而target是不明确的，所以无法直接使用Transformer-XL，论文中提出采用“reparameterize the Transformer(-XL) network”以消除上述的不确定性。</li>
</ul>
<h1 id="排列语言模型"><a href="#排列语言模型" class="headerlink" title="排列语言模型"></a>排列语言模型</h1><p>受无序NADE（Neural autoregressive distribution estimation）的想法的启发，提出一个排列组合语言模型，该模型能够保留自回归模型的优点，同时能够捕获双向的上下文信息。例如一个长度为T的序列，其排序组合为T!，如果所有排列组合次序的参数共享，那么模型应该会从左右两个方向的所有位置收集到信息。但是由于遍历 T! 种路径计算量非常大（对于10个词的句子，10!=3628800）。因此实际只能随机的采样 T! 里的部分排列，并求期望；<br><img src="https://img-blog.csdnimg.cn/20210401224809488.png#pic_center" alt="在这里插入图片描述"></p>
<p>为了更好的理解，看下面这张图：<br><img src="https://img-blog.csdnimg.cn/20210401225106603.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RCQ18xMjE=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>假设输入的序列是[1,2,3,4], 排列共有4x3x2=24种，选其中的四种分别为[3,2,4,1],[2,4,3,1],[1,4,2,3],[4,3,1,2]。在预测位置3的单词时，第一种排列看不到任何单词，第二种排列能看到[2,4]，第三种排列能看到[1,2,4]，第四种排列能看到[4]，所以预测位置3的单词时，不仅能看到上文[1,2]，也能看到下文的[4]，所以通过这种方式，XLNet模型能同时编码上下文信息。</p>
<blockquote>
<p>PLM的本质就是LM联合概率的多种分解机制的体现，将LM的顺序拆解推广到随机拆解，但是需要保留每个词的原始位置信息（PLM只是语言模型建模方式的因式分解/排列，并不是词的位置信息的重新排列！）</p>
</blockquote>
<p>但是有个问题需要注意，上面提出的排列语言模型，在实现过程中，会存在一个问题，举个例子，还是输入序列[1, 2, 3, 4]肯定会有如下的排列[1, 2, 3, 4]，[1,2,4,3]，第一个排列预测位置3，得到如下公式 $P(3|1,2)$，第二个排列预测位置4,得到如下公式 $P(4|1,2)$，这会造成预测出位置3的单词和位置4的单词是一样的，尽管它们所在的位置不同。论文给出具体的公式解释如下：<br><img src="https://img-blog.csdnimg.cn/2021040122582989.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RCQ18xMjE=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>那怎么解决没有目标(target)位置信息的问题？那就是下面要讲的Two-Stream Self-Attention。</p>
<h1 id="Two-Stream-Self-Attention"><a href="#Two-Stream-Self-Attention" class="headerlink" title="Two-Stream Self-Attention"></a>Two-Stream Self-Attention</h1><p>除了上述之外，模型的实现过程中还有两点要求</p>
<ul>
<li>在预测当前单词的时候，只能使用当前单词的位置信息，不能使用单词的内容信息。</li>
<li>在预测其他单词的时候，可以使用当前单词的内容信息</li>
</ul>
<p>为了满足同时这两个要求，XLNet提出了双流自注意力机制，结构如下：<br><img src="https://img-blog.csdnimg.cn/20210401233224610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RCQ18xMjE=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p>下文用 $g_{z_t}$ 表示，上下文的内容信息用 $x_{z&lt;t}$ 表示，目标的位置信息 $z_t$ ，目标的内容信息 $x_{z_t}$</p>
</blockquote>
<ul>
<li>content stream：上面图(a)中，$h_{z_t}^{(m)}\leftarrow Attention(Q=h_{z_t}^{(m-1)},KV=h_{z&lt;t}^{(m-1)};\theta)$，预测其他单词时，使用自己的内容信息 $h_1^{(0)}$，即Content 流主要为 Query 流提供其它词的内容向量，包含位置信息和内容信息</li>
<li>query stream：上面图(b)中，$g_{z_t}^{(m)}\leftarrow Attention(Q=g_{z_t}^{(m-1)},KV=h_{z&lt;t}^{(m-1)};\theta)$，预测当前单词时，不能使用当前单词内容信息 $h_1^{(0)}$，Query 流就为了预测当前词，只包含位置信息，不包含词的内容信息；</li>
<li>总流程：上图(c)中，首先，第一层的查询流是随机初始化了一个向量即 $g_i^{(0)}=w$，内容流是采用的词向量即 $h_i^{(0)}=e(x_i)$，self-attention的计算过程中两个流的网络权重是共享的，最后在微调阶段，只需要简单的把query stream移除，只采用content stream即可。</li>
</ul>
<h1 id="集成Transformer-XL"><a href="#集成Transformer-XL" class="headerlink" title="集成Transformer-XL"></a>集成Transformer-XL</h1><p>除了上文提到的优化点，作者还将transformer-xl的两个最重要的技术点应用了进来，即相对位置编码与片段循环机制。我们先看下recurrence mechanism（不采用BPTT方式求导）。</p>
<ul>
<li>前一个segment计算的representation被修复并缓存，以便在模型处理下一个新的segment时作为扩展上下文resume；</li>
<li>最大可能依赖关系长度增加了N倍，其中N表示网络的深度；</li>
<li>解决了上下文碎片问题，为新段前面的token提供了必要的上下文；</li>
<li>由于不需要重复计算，Transformer-XL在语言建模任务的评估期间比vanilla Transformer快1800+倍；</li>
</ul>
<p>bert的position embedding采用的是绝对位置编码，但是绝对位置编码在transformer-xl中有一个致命的问题，因为没法区分到底是哪一个片段里的，这就导致了一些位置信息的损失，这里被替换为了transformer-xl中的相对位置编码。假设给定一对位置 $i$ 和 $j$ ，如果 $i$ 和 $j$ 是同一个片段里的那么我们令这个片段编码 $s_{ij}=s_{+}$，如果不在一个片段里则令这个片段编码为 $s_{ij}=s_{-}$，这个值是在训练的过程中得到的，也是用来计算attention weight时候用到的，在传统的transformer中attention weight=$Softmax(\frac{Q\cdot K}{d}V)$，在引入相对位置编码后，首先要计算出 $a_{ij}=(q_i+b)^Ts_{sj}$，其中 $b$也是一个需要训练得到的偏执量，最后把得到的 $a_{ij}$与传统的transformer的weight相加从而得到最终的attention weight。</p>
<p>关于相对位置编码更详细的描述可以参考这篇文章：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/105001610">Transformer改进之相对位置编码(RPE)</a></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>XLNet预训练阶段和BERT差不多，不过去除了Next Sentence Prediction，作者发现该任务对结果的提升并没有太大的影响。输入的值还是 [A, SEP, B, SEP, CLS]的模式，A与B代表的是两个不同的片段。更详细的实现细节可以参考<a target="_blank" rel="noopener" href="https://github.com/zihangdai/xlnet">论文源码</a>。</p>
<p>XLNet的创新点：</p>
<ul>
<li>仍使用自回归语言模型，未解决双向上下文的问题，引入了排列语言模型</li>
<li>排列语言模型在预测时需要target的位置信息，为此引入了Two-Stream:Content流编码到当前时刻的所有内容，而Query流只能参考之前的历史信息以及当前要预测的位置信息</li>
<li>为了解决计算量大的问题，采取随机采样语言排列+只预测1个句子后面的 $\frac{1}{K}$ 的词</li>
<li>融合Transformer-XL的优点，处理过长文本</li>
</ul>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>DengBoCong</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="http://dengbocong.cn/Paper-Reading/faa42cbf3533/">http://dengbocong.cn/Paper-Reading/faa42cbf3533/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Licensed under the Apache License, Version 2.0 (the "License")</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span>Stay hungry, Stay foolish.</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/BERT/"># BERT</a>
                    
                        <a href="/tags/XLNet/"># XLNet</a>
                    
                        <a href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"># 预训练模型</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/Paper-Reading/fee5036f15c4/">论文阅读笔记：一种模型训练模型的开放域问答方法，SOTA！</a>
            
            
            <a class="next" rel="next" href="/Deep-Learning/58cb665371b1/">关于Transformer几个内部细节的总结</a>
            
        </section>


    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© Copyright 2020-2021 DengBoCong. All Rights Reserved. 赣ICP备20002291号</span>
    </div>
</footer>

    </div>
    <div id="u-search">
        <div class="modal">
            <div class="modal-header">
                <div class="container">
                    <form id="u-search-modal-form" class="u-search-modal-form">
                        <button type="submit" class="form-submit-btn">
                            <img src="/image/search.png" class="search-btn-img" />
                        </button>
                        <input placeholder="请输入关键字搜索文章..." class="form-input" onchange="inputChange(event)" id="modal-form-input">
                    </form>
                    <a class="modal-close">x</a>
                </div>
                <div class="search-loading">
                    <div class="search-loading-bar"></div>
                </div>
            </div>
            <div class="modal-body">
            </div>
        </div>
        <div class="modal-overlay"></div>
    </div>
</body>
</html>
